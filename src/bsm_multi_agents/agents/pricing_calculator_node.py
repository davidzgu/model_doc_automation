import os
from pathlib import Path
from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage
from bsm_multi_agents.graph.state import WorkflowState
from bsm_multi_agents.config.llm_config import get_llm
from bsm_multi_agents.agents.mcp_adapter import call_mcp_tool
from bsm_multi_agents.agents.utils import (
    extract_mcp_content, 
    load_tools_from_mcp_and_local, 
    call_local_tool
)




def pricing_calculator_agent_node(state: WorkflowState) -> WorkflowState:
    """
    LangGraph node: LLM planning / explanation step.
    Dynamically fetches tools from the MCP server and binds them to the LLM.
    """
    print("\n>>> [Pricing Calculator Agent] Starting planning...")
    errors = state.get("errors", [])

    if "csv_file_path" not in state or not state["csv_file_path"]:
        errors.append("pricing_calculator_agent_node: csv_file_path is missing")
        state["errors"] = errors
        return state

    server_path = state.get("server_path")
    if not server_path:
        errors.append("pricing_calculator_agent_node: server_path is missing")
        state["errors"] = errors
        return state

    output_dir = state.get("output_dir")
    
    local_tool_folder_path = state.get("local_tool_folder_path", None)
    langchain_tools = load_tools_from_mcp_and_local(server_path, local_tool_folder_path)
    
    llm = get_llm().bind_tools(langchain_tools)
    
    system_prompt = (
        "You are a quantitative calculator agent. "
        "You have access to tools specifically for Greeks calculation via an MCP server, as well as local math tools. "
        "You operate in a ReAct loop: you can call a tool, see the result, and then decide to call another tool or finish. "
        "Use the available tools to process these requests sequentially or in parallel if appropriate. "
        "If you have multiple distinct tasks (e.g. Calculate A, then Calculate B), handle them one by one or together.\n"
        "IMPORTANT: When you have completed ALL requested tasks and saved the results, you MUST output a final text response (e.g. 'Calibration and calculation complete.') with NO tool calls. This will signal the workflow to proceed."
    )
    
    user_prompt = (
        f"Input CSV File: {state['csv_file_path']}\n"
        f"Output Directory: {output_dir}\n\n"
        "Please calculate the Greeks for the options in the input CSV file. "
        "Save the results to the output directory. "
        "Ensure you call the calculation tools."
    )

    messages = list(state.get("messages", []))
    
    # 1. Inject Task (User Prompt) IF NOT returning from a tool call.
    # We assume if the last message is a ToolMessage, we are in the middle of a loop 
    # and don't need to re-state the objective.
    # Otherwise (empty history, or returning from another agent), we append the task.
    is_tool_return = (len(messages) > 0 and isinstance(messages[-1], ToolMessage))
    
    if not is_tool_return:
        messages.append(HumanMessage(content=user_prompt))

    # 2. Prepend System Prompt (Ephemeral: sent to LLM but not saved to state history)
    invocation_messages = [SystemMessage(content=system_prompt)] + messages
         
    
    # Invoke
    try:
        ai_msg = llm.invoke(invocation_messages)
        messages.append(ai_msg)
        state["messages"] = messages
        print(f">>> [Pricing Calculator Agent] Decide to use tools: {[tool['name'] for tool in ai_msg.tool_calls]}")
    except Exception as e:
        errors.append(f"pricing_calculator_agent_node: LLM invocation failed: {e}")
    
    state["errors"] = errors
    return state


def pricing_calculator_tool_node(state: WorkflowState) -> WorkflowState:
    """
    Tool node: Executes tool calls generated by the agent.
    """
    print("\n>>> [Pricing Calculator Tool] Executing tool calls...")
    errors = state.get("errors", [])
    messages = list(state.get("messages", []))
    
    if not messages:
        return state
        
    last_msg = messages[-1]
    if not hasattr(last_msg, "tool_calls") or not last_msg.tool_calls:
        return state
    
    server_path = state.get("server_path")
    if not server_path:
        errors.append("pricing_calculator_tool_node: server_path is missing")
        state["errors"] = errors
        return state

    # Ensure tool_outputs dict exists
    if "tool_outputs" not in state or state["tool_outputs"] is None:
         state["tool_outputs"] = {}

    tool_outputs_msgs = []
    
    for tool_call in last_msg.tool_calls:
        tool_name = tool_call["name"]
        args = tool_call["args"]
        call_id = tool_call["id"]
        print(f">>> [Pricing Calculator Tool] Executing tool calls: {tool_name}")
        
        try:
            # 1. Try Local Tool First
            local_tool_paths = state.get("local_tool_paths", [])
            try:
                raw_result = call_local_tool(tool_name, args=args, local_tool_paths=local_tool_paths)
                result_text = str(raw_result)
            except LookupError:
                # 2. Fallback to MCP Tool
                # print(f"Tool {tool_name} not found locally, trying MCP...")
                raw_result = call_mcp_tool(tool_name, server_path, args)
                result_text = extract_mcp_content(raw_result)

            
            # Create ToolMessage
            tool_outputs_msgs.append(ToolMessage(content=result_text, tool_call_id=call_id, name=tool_name))
            
            # Generic Output Handling: Store by tool name
            state["greeks_results_path"] = result_text.strip()
            
                
        except Exception as e:
            err_msg = f"Error executing {tool_name}: {e}"
            errors.append(err_msg)
            tool_outputs_msgs.append(ToolMessage(content=err_msg, tool_call_id=call_id, is_error=True))
            
    messages.extend(tool_outputs_msgs)
    state["messages"] = messages
    state["errors"] = errors
    return state


if __name__ == "__main__":
    project_root = Path(__file__).resolve().parents[3]
    csv_file_path = str(project_root / "data/input/dummy_options.csv")
    output_dir = str(project_root / "data/cache")
    server_path = str(project_root / "src" / "bsm_multi_agents" / "mcp" / "server.py")
    local_tool_paths = [os.path.join(project_root, "src/bsm_multi_agents/tools/my_add.py")]
    
    state = WorkflowState(
        csv_file_path=csv_file_path, 
        output_dir=output_dir, 
        server_path=server_path,
        local_tool_paths=local_tool_paths,
        errors=[],
        messages=[]
    )
    
    state = pricing_calculator_agent_node(state)
    state = pricing_calculator_tool_node(state)
    
    print(state)
    